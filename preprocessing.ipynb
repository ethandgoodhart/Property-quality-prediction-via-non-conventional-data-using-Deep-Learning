{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2NjEULCABsYy"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#  Fetching data from travelweekly to be used to help train model.\n",
        "#\n",
        "# >>> travelweekly.get_hotel(hotel)\n",
        "#\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "\n",
        "def get_hotel(hotel_name):\n",
        "    try:\n",
        "      url = 'https://www.travelweekly.com/AutoComplete.asmx/GetCompleteList'\n",
        "      headers = {\n",
        "          'content-type': 'application/json; charset=UTF-8',\n",
        "          'origin': 'https://www.travelweekly.com',\n",
        "          'referer': 'https://www.travelweekly.com/Hotels/Destinations,United-States',\n",
        "          'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'\n",
        "      }\n",
        "      data = json.dumps({\"Request\": {\"Term\": hotel_name.split(', an')[0], \"Context\": \"HOT\"}}).encode('utf-8')\n",
        "      response = requests.post(url, headers=headers, data=data)\n",
        "      for res in response.json()['d']:\n",
        "          if res['Type'] == 'HOT' and res['URL'] != None:\n",
        "              r = requests.get(f\"https://www.travelweekly.com{res['URL']}\", headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'})\n",
        "              return extract_hotel_info(r.text)\n",
        "      return {}\n",
        "    except Exception as e:\n",
        "      # print(e)\n",
        "      return {}\n",
        "\n",
        "def extract_hotel_info(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    info = {'travelweekly_year_built': pd.NA, 'travelweekly_num_floors': pd.NA, 'travelweekly_num_rooms': pd.NA, 'travelweekly_chain': '', 'travelweekly_events_num_rooms': pd.NA, 'travelweekly_events_total_sqft': pd.NA, 'travelweekly_min_rate': pd.NA, 'travelweekly_max_rate': pd.NA}\n",
        "    # 'travelweekly_year_renovated': ',\n",
        "    # elif 'Year Last Renovated:' in text:\n",
        "        # info['travelweekly_year_renovated'] = int(text.split('Year Last Renovated:')[1].strip().replace(',', ''))\n",
        "    rooms_div = soup.find('p', class_='hotel-rooms')\n",
        "    if rooms_div:\n",
        "        info['travelweekly_num_rooms'] = int(rooms_div.get_text(strip=True).split('Rooms:')[1].strip().replace(',', ''))\n",
        "    rates_div = soup.find('p', class_='hotel-rates')\n",
        "    if rates_div:\n",
        "        info['travelweekly_min_rate'] = int(rates_div.get_text(strip=True).split('Rates:')[1].split('-')[0].strip().replace(',', '').replace('$', ''))\n",
        "        info['travelweekly_max_rate'] = int(rates_div.get_text(strip=True).split('Rates:')[1].split('-')[1].strip().replace(',', '').replace('$', ''))\n",
        "    details_list = soup.find('div', class_='hotel-information-details')\n",
        "    if details_list:\n",
        "        for li in details_list.find_all('p'):\n",
        "            text = li.get_text(strip=True)\n",
        "            if 'Year Built:' in text:\n",
        "                info['travelweekly_year_built'] = int(text.split('Year Built:')[1].strip().replace(',', ''))\n",
        "            elif 'Number of Floors:' in text:\n",
        "                info['travelweekly_num_floors'] = int(text.split('Number of Floors:')[1].strip().replace(',', ''))\n",
        "            elif 'Chain:' in text:\n",
        "                info['travelweekly_chain'] = text.split('Chain:')[1].strip()\n",
        "    events_list = soup.find('div', class_='event-space row')\n",
        "    if events_list:\n",
        "        for p in events_list.find_all('p'):\n",
        "            text = p.get_text(strip=True)\n",
        "            if 'Total number of meeting rooms:' in text:\n",
        "                info['travelweekly_events_num_rooms'] = int(text.split('Total number of meeting rooms:')[1].strip().replace(',', ''))\n",
        "            if 'Total event space:' in text:\n",
        "                info['travelweekly_events_total_sqft'] = int(text.split('Total event space:')[1].split('sq')[0].strip().replace(',', ''))\n",
        "    return info\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "basic = pd.read_csv('data/final_data.csv')\n",
        "basic = basic.dropna()"
      ],
      "metadata": {
        "id": "ZJPopF9SuQda"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(basic), basic.columns, len(basic.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4ESGTYduRHB",
        "outputId": "07cba016-9d97-42bd-dbb2-f38cd5672985"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2987 Index(['name', 'city', 'Width', 'Height', 'Brightness', 'Color', 'Dominate',\n",
            "       'description', 'stars', 'price', 'rating', 'reviews', 'image', 'images',\n",
            "       'categoryReviews', 'userReviews', 'staff', 'facilities', 'cleanliness',\n",
            "       'comfort', 'valueForMoney', 'location', 'albuquerque', 'austin',\n",
            "       'baltimore', 'bonston', 'calgary', 'charlotte', 'chicago', 'columbus',\n",
            "       'dallas', 'denver', 'detroit', 'el_paso', 'fort_worth', 'fresno',\n",
            "       'houston', 'indianapolis', 'jacksonville', 'kansas', 'las_vegas',\n",
            "       'los_angeles', 'louiseville', 'memphis', 'mesa', 'milwaukee',\n",
            "       'montreal', 'nashville', 'new_york', 'oklahoma_city', 'orlando',\n",
            "       'philadelphia', 'phoenix', 'portland', 'sacramento', 'san_antonio',\n",
            "       'san_diego', 'san_francisco', 'san_jose', 'seattle', 'toronto',\n",
            "       'tucson', 'washington_dc', 'c1', 'c2', 'c3', 'd1', 'd2', 'd3'],\n",
            "      dtype='object') 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "\n",
        "last_city = ''\n",
        "hotels_data = []\n",
        "\n",
        "for index, row in basic.iterrows():\n",
        "    tw_fetched = get_hotel(f\"{row['name']} {row['city'].replace('_', '')}\")\n",
        "    more_booking = []\n",
        "\n",
        "    if tw_fetched and tw_fetched != {}:\n",
        "      if row['city'] != last_city:\n",
        "         last_city = row['city']\n",
        "         with open(f\"data/listings/{row['city']}_hotels.json\", 'r') as file:\n",
        "          hotels_data = json.load(file)\n",
        "\n",
        "      for hotel in hotels_data:\n",
        "        if hotel['name'] == row['name']:\n",
        "          more_booking.append(len(hotel['rooms']))\n",
        "          sqft = [int(f.split('feet')[0]) for f in hotel['rooms'][0]['features'] if 'feetÂ²' in f]\n",
        "          if sqft != []:\n",
        "            more_booking.append(sqft[0])\n",
        "          else:\n",
        "            more_booking.append(pd.NA)\n",
        "          break\n",
        "\n",
        "      rows.append(row.to_list() + list(tw_fetched.values()) + more_booking)\n",
        "    if index % 10 == 0:\n",
        "      print(index, len(rows))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFJoHDuwuWDp",
        "outputId": "22537d2f-c3e6-48f5-9c16-ea9239ecc5be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\n",
            "10 8\n",
            "20 15\n",
            "30 22\n",
            "40 26\n",
            "50 29\n",
            "60 31\n",
            "70 36\n",
            "80 40\n",
            "90 42\n",
            "100 44\n",
            "110 50\n",
            "120 52\n",
            "130 55\n",
            "140 55\n",
            "150 57\n",
            "160 62\n",
            "170 64\n",
            "180 67\n",
            "190 68\n",
            "200 71\n",
            "210 73\n",
            "220 77\n",
            "230 81\n",
            "240 84\n",
            "250 84\n",
            "260 88\n",
            "270 88\n",
            "280 88\n",
            "290 88\n",
            "300 88\n",
            "310 88\n",
            "320 88\n",
            "330 88\n",
            "340 89\n",
            "350 89\n",
            "360 89\n",
            "370 89\n",
            "380 89\n",
            "390 89\n",
            "400 89\n",
            "410 89\n",
            "420 89\n",
            "430 89\n",
            "440 89\n",
            "450 89\n",
            "460 90\n",
            "470 90\n",
            "480 90\n",
            "490 91\n",
            "500 91\n",
            "510 92\n",
            "520 93\n",
            "530 99\n",
            "540 102\n",
            "550 106\n",
            "560 112\n",
            "570 115\n",
            "580 115\n",
            "590 115\n",
            "600 115\n",
            "610 115\n",
            "620 115\n",
            "630 115\n",
            "640 116\n",
            "650 116\n",
            "660 116\n",
            "670 120\n",
            "680 123\n",
            "690 124\n",
            "700 128\n",
            "710 131\n",
            "720 135\n",
            "730 138\n",
            "740 144\n",
            "750 151\n",
            "760 153\n",
            "770 156\n",
            "780 160\n",
            "790 164\n",
            "800 167\n",
            "810 173\n",
            "820 175\n",
            "830 180\n",
            "840 183\n",
            "850 188\n",
            "860 194\n",
            "870 198\n",
            "880 202\n",
            "890 203\n",
            "900 204\n",
            "910 207\n",
            "920 210\n",
            "930 211\n",
            "940 212\n",
            "950 213\n",
            "960 213\n",
            "970 213\n",
            "980 217\n",
            "990 222\n",
            "1000 226\n",
            "1010 228\n",
            "1020 231\n",
            "1030 232\n",
            "1040 232\n",
            "1050 232\n",
            "1060 232\n",
            "1070 232\n",
            "1080 232\n",
            "1090 232\n",
            "1100 233\n",
            "1110 233\n",
            "1120 234\n",
            "1130 234\n",
            "1140 235\n",
            "1150 235\n",
            "1160 235\n",
            "1170 235\n",
            "1180 235\n",
            "1190 235\n",
            "1200 235\n",
            "1210 237\n",
            "1220 237\n",
            "1230 237\n",
            "1240 240\n",
            "1250 243\n",
            "1260 248\n",
            "1270 250\n",
            "1280 253\n",
            "1290 258\n",
            "1300 263\n",
            "1310 270\n",
            "1320 276\n",
            "1330 277\n",
            "1340 280\n",
            "1350 283\n",
            "1360 285\n",
            "1370 288\n",
            "1380 292\n",
            "1390 295\n",
            "1400 301\n",
            "1410 305\n",
            "1420 308\n",
            "1430 310\n",
            "1440 310\n",
            "1450 311\n",
            "1460 313\n",
            "1470 316\n",
            "1480 320\n",
            "1490 323\n",
            "1500 323\n",
            "1510 324\n",
            "1520 325\n",
            "1530 325\n",
            "1540 325\n",
            "1550 325\n",
            "1560 325\n",
            "1570 325\n",
            "1580 325\n",
            "1590 325\n",
            "1600 326\n",
            "1610 326\n",
            "1620 326\n",
            "1630 326\n",
            "1640 326\n",
            "1650 326\n",
            "1660 326\n",
            "1670 326\n",
            "1680 326\n",
            "1690 326\n",
            "1700 327\n",
            "1710 331\n",
            "1720 337\n",
            "1730 344\n",
            "1740 350\n",
            "1750 355\n",
            "1760 362\n",
            "1770 367\n",
            "1780 370\n",
            "1790 375\n",
            "1800 380\n",
            "1810 382\n",
            "1820 389\n",
            "1830 396\n",
            "1840 399\n",
            "1850 405\n",
            "1860 411\n",
            "1870 413\n",
            "1880 414\n",
            "1890 415\n",
            "1900 418\n",
            "1910 421\n",
            "1920 422\n",
            "1930 426\n",
            "1940 431\n",
            "1950 435\n",
            "1960 437\n",
            "1970 440\n",
            "1980 442\n",
            "1990 444\n",
            "2000 446\n",
            "2010 449\n",
            "2020 455\n",
            "2030 458\n",
            "2040 459\n",
            "2050 463\n",
            "2060 465\n",
            "2070 466\n",
            "2080 467\n",
            "2090 467\n",
            "2100 467\n",
            "2110 468\n",
            "2120 468\n",
            "2130 468\n",
            "2140 469\n",
            "2150 471\n",
            "2160 471\n",
            "2170 472\n",
            "2180 476\n",
            "2190 479\n",
            "2200 483\n",
            "2210 483\n",
            "2220 487\n",
            "2230 493\n",
            "2240 497\n",
            "2250 500\n",
            "2260 503\n",
            "2270 505\n",
            "2280 510\n",
            "2290 514\n",
            "2300 517\n",
            "2310 522\n",
            "2320 526\n",
            "2330 530\n",
            "2340 531\n",
            "2350 532\n",
            "2360 532\n",
            "2370 534\n",
            "2380 537\n",
            "2390 538\n",
            "2400 539\n",
            "2410 541\n",
            "2420 541\n",
            "2430 542\n",
            "2440 542\n",
            "2450 542\n",
            "2460 542\n",
            "2470 542\n",
            "2480 542\n",
            "2490 547\n",
            "2500 550\n",
            "2510 553\n",
            "2520 558\n",
            "2530 561\n",
            "2540 566\n",
            "2550 567\n",
            "2560 571\n",
            "2570 575\n",
            "2580 577\n",
            "2590 580\n",
            "2600 583\n",
            "2610 589\n",
            "2620 593\n",
            "2630 597\n",
            "2640 602\n",
            "2650 606\n",
            "2660 609\n",
            "2670 609\n",
            "2680 612\n",
            "2690 613\n",
            "2700 617\n",
            "2710 619\n",
            "2720 624\n",
            "2730 629\n",
            "2740 630\n",
            "2750 632\n",
            "2760 634\n",
            "2770 638\n",
            "2780 640\n",
            "2790 641\n",
            "2800 641\n",
            "2810 641\n",
            "2820 641\n",
            "2830 642\n",
            "2840 642\n",
            "2850 643\n",
            "2860 645\n",
            "2870 646\n",
            "2880 646\n",
            "2890 646\n",
            "2900 646\n",
            "2910 646\n",
            "2920 646\n",
            "2930 646\n",
            "2940 646\n",
            "2950 646\n",
            "2960 647\n",
            "2970 647\n",
            "2980 647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(rows, columns=['name', 'city', 'Width', 'Height', 'Brightness', 'Color', 'Dominate',\n",
        "       'description', 'stars', 'price', 'rating', 'reviews', 'image', 'images',\n",
        "       'categoryReviews', 'userReviews', 'staff', 'facilities', 'cleanliness',\n",
        "       'comfort', 'valueForMoney', 'location', 'albuquerque', 'austin',\n",
        "       'baltimore', 'bonston', 'calgary', 'charlotte', 'chicago', 'columbus',\n",
        "       'dallas', 'denver', 'detroit', 'el_paso', 'fort_worth', 'fresno',\n",
        "       'houston', 'indianapolis', 'jacksonville', 'kansas', 'las_vegas',\n",
        "       'los_angeles', 'louiseville', 'memphis', 'mesa', 'milwaukee',\n",
        "       'montreal', 'nashville', 'new_york', 'oklahoma_city', 'orlando',\n",
        "       'philadelphia', 'phoenix', 'portland', 'sacramento', 'san_antonio',\n",
        "       'san_diego', 'san_francisco', 'san_jose', 'seattle', 'toronto',\n",
        "       'tucson', 'washington_dc', 'c1', 'c2', 'c3', 'd1', 'd2', 'd3',\n",
        "       'travelweekly_year_built', 'travelweekly_num_floors', 'travelweekly_num_rooms', 'travelweekly_chain', 'travelweekly_events_num_rooms', 'travelweekly_events_total_sqft', 'travelweekly_min_rate', 'travelweekly_max_rate',\n",
        "       'num_room_types', 'standard_room_sqft'\n",
        "])\n",
        "# .select_dtypes(['number'])\n",
        "# df = df.dropna()\n",
        "df.to_csv('custom_dataset.csv')"
      ],
      "metadata": {
        "id": "cr_B9BUk1GIO"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}